name: ğŸ›ï¸ æ—¶å°šæ•°æ®åˆ†æç³»ç»Ÿ CI/CD

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # æ¯å¤©å‡Œæ™¨2ç‚¹è¿è¡Œ (UTCæ—¶é—´ 02:00)
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      platform:
        description: 'é€‰æ‹©æ•°æ®æŠ“å–å¹³å°'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - amazon
          - tiktok

env:
  PYTHON_VERSION: '3.9'
  NODE_VERSION: '18'

jobs:
  # ä»£ç è´¨é‡æ£€æŸ¥
  lint-and-test:
    runs-on: ubuntu-latest
    
    steps:
    - name: ğŸ“¥ æ£€å‡ºä»£ç 
      uses: actions/checkout@v4
      
    - name: ğŸ è®¾ç½®Pythonç¯å¢ƒ
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: ğŸ“¦ ç¼“å­˜pipä¾èµ–
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: ğŸ”§ å®‰è£…Pythonä¾èµ–
      run: |
        python -m pip install --upgrade pip
        pip install flake8 black isort
        pip install -r code/requirements.txt
        pip install -r code/requirements_data_cleaner.txt
        
    - name: ğŸ¨ ä»£ç æ ¼å¼æ£€æŸ¥ (Black)
      run: |
        black --check --diff code/ || true
        black --check --diff tests/ || true
        
    - name: ğŸ” ä»£ç é£æ ¼æ£€æŸ¥ (Flake8)
      run: |
        flake8 code/ tests/ || true
        
    - name: ğŸ“Š æ•°æ®å®Œæ•´æ€§æ£€æŸ¥ (isort)
      run: |
        isort --check-only --diff code/ || true
        
    - name: ğŸ“ è¿è¡Œæµ‹è¯•
      run: |
        cd tests
        python run_all_tests.py
        
    - name: ğŸ“ˆ ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
      if: always()
      uses: codecov/codecov-action@v3
      with:
        file: ./tests/coverage.xml
        flags: unittests
        name: codecov-umbrella

  # æ•°æ®åº“å’Œä¾èµ–å®‰è£…
  setup-database:
    runs-on: ubuntu-latest
    needs: lint-and-test
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_USER: postgres
          POSTGRES_DB: fashion_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
          
    steps:
    - name: ğŸ“¥ æ£€å‡ºä»£ç 
      uses: actions/checkout@v4
      
    - name: ğŸ è®¾ç½®Pythonç¯å¢ƒ
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: ğŸ“¦ å®‰è£…ä¾èµ–
      run: |
        python -m pip install --upgrade pip
        pip install psycopg2-binary
        pip install -r code/requirements.txt
        
    - name: ğŸ—ƒï¸ åˆå§‹åŒ–æ•°æ®åº“
      run: |
        cd code
        python -c "
        import os
        os.environ['DATABASE_URL'] = 'postgresql://postgres:postgres@localhost:5432/fashion_db'
        from database import Database
        db = Database()
        db.create_tables()
        print('âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ')
        "

  # æ•°æ®æŠ“å–ä»»åŠ¡
  scrape-data:
    runs-on: ubuntu-latest
    needs: setup-database
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    
    strategy:
      matrix:
        platform: [amazon, tiktok]
        include:
          - platform: amazon
            category: "T-Shirt"
          - platform: tiktok
            category: "Printed"
            
    steps:
    - name: ğŸ“¥ æ£€å‡ºä»£ç 
      uses: actions/checkout@v4
      
    - name: ğŸ è®¾ç½®Pythonç¯å¢ƒ
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: ğŸ”§ å®‰è£…ç³»ç»Ÿä¾èµ–
      run: |
        sudo apt-get update
        sudo apt-get install -y chromium-browser
        
    - name: ğŸ“¦ å®‰è£…Pythonä¾èµ–
      run: |
        python -m pip install --upgrade pip
        pip install -r code/requirements.txt
        pip install -r code/requirements_data_cleaner.txt
        
    - name: âš™ï¸ é…ç½®ç¯å¢ƒå˜é‡
      run: |
        echo "ENVIRONMENT=production" >> $GITHUB_ENV
        echo "DATABASE_URL=sqlite:///data/fashion_data.db" >> $GITHUB_ENV
        # ä½¿ç”¨æ¨¡æ‹ŸAPIå¯†é’¥è¿›è¡Œæµ‹è¯•
        echo "AMAZON_ACCESS_KEY=test_key" >> $GITHUB_ENV
        echo "TIKHUB_API_KEY=test_key" >> $GITHUB_ENV
        
    - name: ğŸ—ƒï¸ åˆå§‹åŒ–æ•°æ®åº“
      run: |
        mkdir -p data
        cd code
        python -c "
        from database import Database
        db = Database()
        db.create_tables()
        print('âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ')
        "
        
    - name: ğŸ•·ï¸ æ‰§è¡Œæ•°æ®æŠ“å–
      run: |
        cd code
        python main.py scrape --platform ${{ matrix.platform }} --category "${{ matrix.category }}"
        
    - name: ğŸ§¹ æ•°æ®æ¸…æ´—
      run: |
        cd code
        python main.py clean
        
    - name: ğŸ“Š ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
      run: |
        cd code
        python main.py stats > ../data/scraping_report_$(date +%Y%m%d).txt
        
    - name: ğŸ’¾ å­˜å‚¨æ•°æ®æ–‡ä»¶
      uses: actions/upload-artifact@v3
      with:
        name: scraped-data-${{ matrix.platform }}
        path: |
          data/
          code/data/
          
    - name: ğŸ“ˆ ä¸Šä¼ çˆ¬å–æŠ¥å‘Š
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: scraping-report-${{ matrix.platform }}
        path: data/scraping_report_*.txt

  # éƒ¨ç½²åˆ°Vercel (å‰ç«¯)
  deploy-frontend:
    runs-on: ubuntu-latest
    needs: [lint-and-test, scrape-data]
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: ğŸ“¥ æ£€å‡ºä»£ç 
      uses: actions/checkout@v4
      
    - name: ğŸŒ å®‰è£…Vercel CLI
      run: npm install --global vercel@canary
      
    - name: ğŸš€ éƒ¨ç½²åˆ°Vercel
      run: |
        cd fashion-dashboard
        vercel --prod --yes --token ${{ secrets.VERCEL_TOKEN }} --scope ${{ secrets.VERCEL_ORG_ID }}
      env:
        VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}
        VERCEL_ORG_ID: ${{ secrets.VERCEL_ORG_ID }}
        VERCEL_PROJECT_ID: ${{ secrets.VERCEL_PROJECT_ID }}

  # éƒ¨ç½²åˆ°AWS Lambda (åç«¯)
  deploy-backend:
    runs-on: ubuntu-latest
    needs: [lint-and-test, scrape-data]
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: ğŸ“¥ æ£€å‡ºä»£ç 
      uses: actions/checkout@v4
      
    - name: ğŸ è®¾ç½®Pythonç¯å¢ƒ
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: ğŸ“¦ å®‰è£…ä¾èµ–
      run: |
        python -m pip install --upgrade pip
        pip install -r code/requirements.txt
        pip install boto3
        
    - name: ğŸ”§ æ‰“åŒ…Lambdaå‡½æ•°
      run: |
        cd deployment/cloud-function
        zip -r lambda_function.zip lambda_scraper.py
        
    - name: ğŸš€ éƒ¨ç½²åˆ°AWS Lambda
      if: env.AWS_ACCESS_KEY_ID != ''
      run: |
        aws lambda update-function-code \
          --function-name fashion-scraper \
          --zip-file fileb://lambda_function.zip
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_REGION: us-east-1

  # å®¹å™¨åŒ–éƒ¨ç½²
  deploy-docker:
    runs-on: ubuntu-latest
    needs: [lint-and-test]
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: ğŸ“¥ æ£€å‡ºä»£ç 
      uses: actions/checkout@v4
      
    - name: ğŸ” ç™»å½•Docker Hub
      if: env.DOCKERHUB_USERNAME != ''
      uses: docker/login-action@v2
      with:
        username: ${{ secrets.DOCKERHUB_USERNAME }}
        password: ${{ secrets.DOCKERHUB_TOKEN }}
        
    - name: ğŸ—ï¸ æ„å»ºDockeré•œåƒ
      run: |
        docker build -t fashion-analyzer:latest .
        docker tag fashion-analyzer:latest ${{ secrets.DOCKERHUB_USERNAME }}/fashion-analyzer:latest
        
    - name: ğŸš€ æ¨é€åˆ°Docker Hub
      if: env.DOCKERHUB_USERNAME != ''
      run: |
        docker push ${{ secrets.DOCKERHUB_USERNAME }}/fashion-analyzer:latest
        
    - name: ğŸ³ æ¨é€åˆ°GitHub Container Registry
      uses: docker/build-push-action@v4
      with:
        context: .
        push: true
        tags: ghcr.io/${{ github.repository_owner }}/fashion-analyzer:latest
        cache-from: type=gha
        cache-to: type=gha,mode=max

  # å‘é€é€šçŸ¥
  notify:
    runs-on: ubuntu-latest
    needs: [lint-and-test, deploy-frontend, deploy-backend, deploy-docker]
    if: always()
    
    steps:
    - name: ğŸ“Š å·¥ä½œæµçŠ¶æ€æ€»ç»“
      uses: actions/github-script@v6
      with:
        script: |
          const jobs = ['lint-and-test', 'setup-database', 'scrape-data', 'deploy-frontend', 'deploy-backend', 'deploy-docker'];
          let message = 'ğŸ›ï¸ æ—¶å°šæ•°æ®åˆ†æç³»ç»Ÿ - CI/CD å®Œæˆ\\n\\n';
          
          for (const job of jobs) {
            const status = context.payload.workflow_runs[0].jobs.find(j => j.name === job)?.conclusion || 'skipped';
            const emoji = status === 'success' ? 'âœ…' : status === 'failure' ? 'âŒ' : 'â­ï¸';
            message += `${emoji} ${job}: ${status}\\n`;
          }
          
          if (context.eventName === 'schedule') {
            message += '\\nâ° å®šæ—¶ä»»åŠ¡å®Œæˆ';
          }
          
          console.log(message);

  # æ€§èƒ½æµ‹è¯•å’Œç›‘æ§
  performance-test:
    runs-on: ubuntu-latest
    needs: deploy-frontend
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: ğŸ“¥ æ£€å‡ºä»£ç 
      uses: actions/checkout@v4
      
    - name: ğŸ§ª å®‰è£…Playwright
      run: |
        pip install playwright
        playwright install chromium
        
    - name: ğŸš€ å¯åŠ¨æœ¬åœ°æœåŠ¡å™¨
      run: |
        cd fashion-dashboard
        python -m http.server 9000 &
        
    - name: âš¡ æ€§èƒ½æµ‹è¯•
      run: |
        python tests/web_performance.py --url http://localhost:9000
        
    - name: ğŸ“ˆ ä¸Šä¼ æ€§èƒ½æŠ¥å‘Š
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: performance-report
        path: performance_report.json

# ==============================================================================
# ç¯å¢ƒå˜é‡é…ç½®æŒ‡å—
# ==============================================================================
# åœ¨GitHubä»“åº“è®¾ç½®ä¸­æ·»åŠ ä»¥ä¸‹secrets:
# 
# VERCEL_TOKEN - Vercelè®¿é—®ä»¤ç‰Œ
# VERCEL_ORG_ID - Vercelç»„ç»‡ID
# VERCEL_PROJECT_ID - Vercelé¡¹ç›®ID
# 
# AWS_ACCESS_KEY_ID - AWSè®¿é—®å¯†é’¥ID
# AWS_SECRET_ACCESS_KEY - AWSå¯†é’¥
# 
# DOCKERHUB_USERNAME - Docker Hubç”¨æˆ·å
# DOCKERHUB_TOKEN - Docker Hubè®¿é—®ä»¤ç‰Œ
# 
# æˆ–è€…åœ¨.envæ–‡ä»¶ä¸­é…ç½®:
# TIKHUB_API_KEY=your_tikhub_key
# AMAZON_ACCESS_KEY=your_amazon_key
# AMAZON_SECRET_KEY=your_amazon_secret
# SUPABASE_URL=your_supabase_url
# SUPABASE_ANON_KEY=your_supabase_key
#