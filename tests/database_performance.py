#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“æ€§èƒ½æµ‹è¯•æ¨¡å—

æµ‹è¯•å†…å®¹åŒ…æ‹¬ï¼š
1. SQLiteæ•°æ®åº“è¯»å†™æ€§èƒ½
2. å¤§é‡æ•°æ®æŸ¥è¯¢é€Ÿåº¦
3. å¹¶å‘è®¿é—®ç¨³å®šæ€§
4. ç´¢å¼•ä¼˜åŒ–æ•ˆæœ

æµ‹è¯•æŒ‡æ ‡ï¼š
- æ•°æ®åº“æŸ¥è¯¢: < 100ms
- æ•°æ®æ’å…¥é€Ÿåº¦: > 1000 records/second
- å¹¶å‘è¿æ¥æ•°: > 50
"""

import sqlite3
import time
import threading
import random
import statistics
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any, Tuple
import json
from contextlib import contextmanager
from pathlib import Path
import logging

# å¯¼å…¥æ•°æ®åº“ç®¡ç†å™¨
import sys
sys.path.append(str(Path(__file__).parent.parent / "code"))
from database import DatabaseManager, DatabaseConfig, create_sample_data

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DatabasePerformanceTest:
    """æ•°æ®åº“æ€§èƒ½æµ‹è¯•ç±»"""
    
    def __init__(self, test_db_path: str = "tests/test_performance.db"):
        """åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ"""
        self.test_db_path = Path(test_db_path)
        self.test_db_path.parent.mkdir(exist_ok=True)
        
        # é…ç½®æµ‹è¯•æ•°æ®åº“
        self.config = DatabaseConfig(
            db_path=str(self.test_db_path),
            backup_dir=str(self.test_db_path.parent / "backup"),
            connection_pool_size=20
        )
        
        self.db_manager = DatabaseManager(self.config)
        self.test_results = {}
        
    def setup_test_data(self, data_sizes: List[int] = [50, 200, 500]):
        """è®¾ç½®æµ‹è¯•æ•°æ®"""
        logger.info("å¼€å§‹å‡†å¤‡æµ‹è¯•æ•°æ®...")
        
        for size in data_sizes:
            logger.info(f"ç”Ÿæˆ {size} æ¡æµ‹è¯•æ•°æ®...")
            
            # ç”Ÿæˆæµ‹è¯•äº§å“æ•°æ®
            products = []
            for i in range(size):
                product = {
                    'product_name': f"æµ‹è¯•äº§å“ {i+1}",
                    'platform': random.choice(['tiktok', 'amazon']),
                    'category': random.choice(['tshirt', 'hoodie', 'sweatshirt']),
                    'price': round(random.uniform(15.99, 89.99), 2),
                    'original_price': round(random.uniform(20.99, 99.99), 2),
                    'currency': 'USD',
                    'sales_count': random.randint(100, 10000),
                    'rating': round(random.uniform(3.0, 5.0), 1),
                    'review_count': random.randint(10, 500),
                    'product_url': f"https://test.com/product/{i+1}",
                    'store_url': f"https://test.com/store/merchant_{i%10}",
                    'store_name': f"åº—é“º {i%10}",
                    'main_image_url': f"https://cdn.test.com/product_{i+1}.jpg",
                    'image_urls': json.dumps([f"https://cdn.test.com/product_{i+1}_{j}.jpg" for j in range(3)]),
                    'like_count': random.randint(50, 1000),
                    'share_count': random.randint(10, 200),
                    'comment_count': random.randint(5, 100),
                    'view_count': random.randint(500, 5000),
                    'data_source': 'performance_test',
                    'keywords': json.dumps(['hot', 'trending', 'fashion']),
                    'notes': f'æ€§èƒ½æµ‹è¯•æ•°æ® #{i+1}'
                }
                products.append(product)
            
            # æ‰¹é‡æ’å…¥æ•°æ®
            start_time = time.time()
            for product in products:
                self.db_manager.insert_product(product)
            
            insert_time = time.time() - start_time
            rate = size / insert_time
            
            logger.info(f"æ’å…¥ {size} æ¡æ•°æ®ç”¨æ—¶: {insert_time:.2f}s, é€Ÿç‡: {rate:.1f} records/s")
            
            # è®°å½•ç»“æœ
            self.test_results[f'insert_{size}_records'] = {
                'count': size,
                'time': insert_time,
                'rate': rate
            }
    
    def test_query_performance(self):
        """æµ‹è¯•æŸ¥è¯¢æ€§èƒ½"""
        logger.info("å¼€å§‹æµ‹è¯•æŸ¥è¯¢æ€§èƒ½...")
        
        test_queries = [
            ('æŒ‰å¹³å°ç­›é€‰', lambda: self.db_manager.get_products(platform='tiktok', limit=100)),
            ('æŒ‰åˆ†ç±»ç­›é€‰', lambda: self.db_manager.get_products(category='hoodie', limit=100)),
            ('å¹³å°+åˆ†ç±»ç­›é€‰', lambda: self.db_manager.get_products(platform='amazon', category='tshirt', limit=100)),
            ('è·å–å…¨éƒ¨æ•°æ®', lambda: self.db_manager.get_products(limit=1000)),
            ('è·å–ç»Ÿè®¡ä¿¡æ¯', lambda: self.db_manager.get_database_stats())
        ]
        
        query_results = {}
        
        for query_name, query_func in test_queries:
            times = []
            for _ in range(10):  # æ¯ä¸ªæŸ¥è¯¢è¿è¡Œ10æ¬¡å–å¹³å‡
                start_time = time.time()
                result = query_func()
                end_time = time.time()
                times.append(end_time - start_time)
            
            avg_time = statistics.mean(times) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            min_time = min(times) * 1000
            max_time = max(times) * 1000
            std_dev = statistics.stdev(times) * 1000 if len(times) > 1 else 0
            
            query_results[query_name] = {
                'avg_time_ms': round(avg_time, 2),
                'min_time_ms': round(min_time, 2),
                'max_time_ms': round(max_time, 2),
                'std_dev_ms': round(std_dev, 2),
                'target_met': avg_time < 100  # < 100msç›®æ ‡
            }
            
            logger.info(f"{query_name}: å¹³å‡ {avg_time:.2f}ms (ç›®æ ‡: < 100ms)")
        
        self.test_results['query_performance'] = query_results
    
    def test_concurrent_access(self, max_workers: int = 10):
        """æµ‹è¯•å¹¶å‘è®¿é—®æ€§èƒ½"""
        logger.info(f"å¼€å§‹æµ‹è¯•å¹¶å‘è®¿é—® (æœ€å¤š {max_workers} ä¸ªå¹¶å‘)...")
        
        concurrent_results = {}
        
        def concurrent_query_worker(worker_id):
            """å¹¶å‘æŸ¥è¯¢å·¥ä½œå‡½æ•°"""
            times = []
            errors = 0
            
            for _ in range(20):  # æ¯ä¸ªå·¥ä½œçº¿ç¨‹æ‰§è¡Œ20æ¬¡æŸ¥è¯¢
                try:
                    start_time = time.time()
                    self.db_manager.get_products(platform='tiktok', limit=50)
                    end_time = time.time()
                    times.append(end_time - start_time)
                except Exception as e:
                    errors += 1
            
            return {
                'worker_id': worker_id,
                'times': times,
                'errors': errors,
                'success_rate': (20 - errors) / 20
            }
        
        # æ‰§è¡Œå¹¶å‘æµ‹è¯•
        start_time = time.time()
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [executor.submit(concurrent_query_worker, i) for i in range(max_workers)]
            
            worker_results = []
            for future in as_completed(futures):
                try:
                    result = future.result()
                    worker_results.append(result)
                except Exception as e:
                    logger.error(f"å¹¶å‘æµ‹è¯•å‡ºé”™: {e}")
        
        total_time = time.time() - start_time
        
        # åˆ†æç»“æœ
        all_times = []
        total_errors = 0
        success_rates = []
        
        for result in worker_results:
            all_times.extend(result['times'])
            total_errors += result['errors']
            success_rates.append(result['success_rate'])
        
        concurrent_results = {
            'total_workers': max_workers,
            'total_time': total_time,
            'avg_query_time_ms': round(statistics.mean(all_times) * 1000, 2),
            'min_query_time_ms': round(min(all_times) * 1000, 2),
            'max_query_time_ms': round(max(all_times) * 1000, 2),
            'total_queries': len(all_times),
            'total_errors': total_errors,
            'overall_success_rate': (len(all_times) - total_errors) / len(all_times),
            'avg_worker_success_rate': statistics.mean(success_rates),
            'target_met': total_errors == 0 and statistics.mean(all_times) < 0.1
        }
        
        self.test_results['concurrent_access'] = concurrent_results
        
        logger.info(f"å¹¶å‘æµ‹è¯•å®Œæˆ: {len(all_times)} æ¬¡æŸ¥è¯¢, æˆåŠŸç‡: {concurrent_results['overall_success_rate']:.2%}")
    
    def test_index_performance(self):
        """æµ‹è¯•ç´¢å¼•ä¼˜åŒ–æ•ˆæœ"""
        logger.info("æµ‹è¯•ç´¢å¼•ä¼˜åŒ–æ•ˆæœ...")
        
        # åˆ›å»ºæ— ç´¢å¼•çš„æµ‹è¯•è¡¨
        def test_without_index():
            with sqlite3.connect(':memory:') as conn:
                cursor = conn.cursor()
                
                # åˆ›å»ºæ— ç´¢å¼•è¡¨
                cursor.execute("""
                    CREATE TABLE test_products (
                        id INTEGER PRIMARY KEY,
                        name TEXT,
                        platform TEXT,
                        category TEXT,
                        price REAL
                    )
                """)
                
                # æ’å…¥å¤§é‡æ•°æ®
                for i in range(1000):
                    cursor.execute("""
                        INSERT INTO test_products (name, platform, category, price)
                        VALUES (?, ?, ?, ?)
                    """, (f"Product {i}", random.choice(['tiktok', 'amazon']), 
                         random.choice(['tshirt', 'hoodie', 'sweatshirt']), 
                         random.uniform(15, 89)))
                
                conn.commit()
                
                # æµ‹è¯•æŸ¥è¯¢æ€§èƒ½
                start_time = time.time()
                for _ in range(100):
                    cursor.execute("""
                        SELECT * FROM test_products 
                        WHERE platform = ? AND category = ?
                    """, ('tiktok', 'hoodie'))
                    cursor.fetchall()
                
                return time.time() - start_time
        
        # åˆ›å»ºæœ‰ç´¢å¼•çš„æµ‹è¯•è¡¨
        def test_with_index():
            with sqlite3.connect(':memory:') as conn:
                cursor = conn.cursor()
                
                # åˆ›å»ºæœ‰ç´¢å¼•è¡¨
                cursor.execute("""
                    CREATE TABLE test_products (
                        id INTEGER PRIMARY KEY,
                        name TEXT,
                        platform TEXT,
                        category TEXT,
                        price REAL
                    )
                """)
                
                # åˆ›å»ºç´¢å¼•
                cursor.execute("CREATE INDEX idx_platform_category ON test_products(platform, category)")
                
                # æ’å…¥ç›¸åŒæ•°æ®
                for i in range(1000):
                    cursor.execute("""
                        INSERT INTO test_products (name, platform, category, price)
                        VALUES (?, ?, ?, ?)
                    """, (f"Product {i}", random.choice(['tiktok', 'amazon']), 
                         random.choice(['tshirt', 'hoodie', 'sweatshirt']), 
                         random.uniform(15, 89)))
                
                conn.commit()
                
                # æµ‹è¯•æŸ¥è¯¢æ€§èƒ½
                start_time = time.time()
                for _ in range(100):
                    cursor.execute("""
                        SELECT * FROM test_products 
                        WHERE platform = ? AND category = ?
                    """, ('tiktok', 'hoodie'))
                    cursor.fetchall()
                
                return time.time() - start_time
        
        # æ‰§è¡Œæµ‹è¯•
        time_without_index = test_without_index()
        time_with_index = test_with_index()
        
        improvement = ((time_without_index - time_with_index) / time_without_index) * 100
        
        index_results = {
            'time_without_index': round(time_without_index, 4),
            'time_with_index': round(time_with_index, 4),
            'improvement_percent': round(improvement, 2),
            'target_met': improvement > 50  # ç›®æ ‡æå‡50%ä»¥ä¸Š
        }
        
        self.test_results['index_performance'] = index_results
        
        logger.info(f"ç´¢å¼•ä¼˜åŒ–: æ€§èƒ½æå‡ {improvement:.1f}%")
    
    def test_memory_usage(self):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        logger.info("æµ‹è¯•å†…å­˜ä½¿ç”¨æƒ…å†µ...")
        
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # æ‰§è¡Œå¤§é‡æŸ¥è¯¢æµ‹è¯•å†…å­˜å˜åŒ–
        for _ in range(10):
            products = self.db_manager.get_products(limit=1000)
        
        peak_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        memory_results = {
            'initial_memory_mb': round(initial_memory, 2),
            'peak_memory_mb': round(peak_memory, 2),
            'memory_increase_mb': round(peak_memory - initial_memory, 2),
            'target_met': peak_memory - initial_memory < 100  # å¢é•¿ä¸è¶…è¿‡100MB
        }
        
        self.test_results['memory_usage'] = memory_results
        
        logger.info(f"å†…å­˜ä½¿ç”¨: {initial_memory:.1f}MB -> {peak_memory:.1f}MB")
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æ€§èƒ½æµ‹è¯•"""
        logger.info("å¼€å§‹æ•°æ®åº“æ€§èƒ½æµ‹è¯•...")
        
        try:
            # å‡†å¤‡æµ‹è¯•æ•°æ®
            self.setup_test_data([50, 200, 500])
            
            # è¿è¡Œå„é¡¹æµ‹è¯•
            self.test_query_performance()
            self.test_concurrent_access(10)
            self.test_index_performance()
            self.test_memory_usage()
            
            logger.info("æ•°æ®åº“æ€§èƒ½æµ‹è¯•å®Œæˆ")
            
        except Exception as e:
            logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            raise
        
        finally:
            # æ¸…ç†æµ‹è¯•æ•°æ®
            self.cleanup()
    
    def cleanup(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        try:
            self.db_manager.close()
            if self.test_db_path.exists():
                self.test_db_path.unlink()
            logger.info("æµ‹è¯•ç¯å¢ƒæ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.warning(f"æ¸…ç†ç¯å¢ƒæ—¶å‡ºé”™: {e}")
    
    def generate_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š"""
        return {
            'test_type': 'database_performance',
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'database_type': 'SQLite',
            'test_results': self.test_results,
            'summary': self._generate_summary()
        }
    
    def _generate_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆæµ‹è¯•æ‘˜è¦"""
        summary = {
            'total_tests': 0,
            'passed_tests': 0,
            'failed_tests': 0,
            'overall_status': 'unknown'
        }
        
        # æ£€æŸ¥å„é¡¹æµ‹è¯•æ˜¯å¦è¾¾æ ‡
        test_targets = {
            'query_performance': lambda results: all(
                result['target_met'] for result in results.values()
            ),
            'concurrent_access': lambda results: results['target_met'],
            'index_performance': lambda results: results['target_met'],
            'memory_usage': lambda results: results['target_met']
        }
        
        for test_name, target_func in test_targets.items():
            if test_name in self.test_results:
                summary['total_tests'] += 1
                try:
                    if target_func(self.test_results[test_name]):
                        summary['passed_tests'] += 1
                    else:
                        summary['failed_tests'] += 1
                except Exception:
                    summary['failed_tests'] += 1
        
        if summary['passed_tests'] == summary['total_tests']:
            summary['overall_status'] = 'passed'
        elif summary['passed_tests'] > 0:
            summary['overall_status'] = 'partial'
        else:
            summary['overall_status'] = 'failed'
        
        return summary


def run_database_performance_tests():
    """è¿è¡Œæ•°æ®åº“æ€§èƒ½æµ‹è¯•çš„ä¸»å‡½æ•°"""
    print("=" * 60)
    print("æ•°æ®åº“æ€§èƒ½æµ‹è¯•")
    print("=" * 60)
    
    tester = DatabasePerformanceTest()
    
    try:
        # è¿è¡Œæµ‹è¯•
        tester.run_all_tests()
        
        # ç”ŸæˆæŠ¥å‘Š
        report = tester.generate_report()
        
        # è¾“å‡ºç»“æœ
        print("\nğŸ“Š æµ‹è¯•ç»“æœæ‘˜è¦:")
        summary = report['summary']
        print(f"   æ€»æµ‹è¯•é¡¹: {summary['total_tests']}")
        print(f"   é€šè¿‡æµ‹è¯•: {summary['passed_tests']}")
        print(f"   å¤±è´¥æµ‹è¯•: {summary['failed_tests']}")
        print(f"   æ•´ä½“çŠ¶æ€: {summary['overall_status']}")
        
        # è¯¦ç»†ç»“æœ
        print("\nğŸ“ˆ è¯¦ç»†æµ‹è¯•ç»“æœ:")
        for test_name, results in report['test_results'].items():
            print(f"\n{test_name}:")
            if isinstance(results, dict):
                for key, value in results.items():
                    if key.endswith('_met'):  # è·³è¿‡å¸ƒå°”ç»“æœ
                        status = "âœ…" if value else "âŒ"
                        print(f"   {status} {key}: {value}")
                    else:
                        print(f"   {key}: {value}")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_file = Path("tests/database_performance_report.json")
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        return report
        
    except Exception as e:
        logger.error(f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        raise
    finally:
        tester.cleanup()


if __name__ == "__main__":
    run_database_performance_tests()